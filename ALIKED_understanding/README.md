# ALIKED Understanding - ç°¡ç•¥åŒ–ç–‘ä¼¼ã‚³ãƒ¼ãƒ‰é›†

ALIKED (A LIghter Keypoint and descriptor Extraction network with Deformable transformation) ã®ç†è§£ã‚’ç›®çš„ã¨ã—ãŸç°¡ç•¥åŒ–ç–‘ä¼¼ã‚³ãƒ¼ãƒ‰é›†ã§ã™ã€‚

è«–æ–‡: [ALIKED: A Lighter Keypoint and Descriptor Extraction Network via Deformable Transformation](https://arxiv.org/abs/2304.03608)

## ğŸ“‹ ç›®æ¬¡

- [æ¦‚è¦](#æ¦‚è¦)
- [ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å…¨ä½“åƒ](#ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å…¨ä½“åƒ)
- [ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ](#ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ)
- [ALIKEDã®ä¸»è¦ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³](#alikedã®ä¸»è¦ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³)
- [å‡¦ç†ãƒ•ãƒ­ãƒ¼è©³ç´°](#å‡¦ç†ãƒ•ãƒ­ãƒ¼è©³ç´°)
- [å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ](#å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ)
- [å½¢çŠ¶ã‚¬ã‚¤ãƒ‰](#å½¢çŠ¶ã‚¬ã‚¤ãƒ‰)
- [FAQ](#faq)

---

## æ¦‚è¦

**ALIKEDã®ç‰¹å¾´:**
- **è¶…è»½é‡**: 0.19M (Tiny) ~ 0.98M (Normal-32) ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
- **é«˜é€Ÿ**: 125 FPS (Tiny) ~ 75 FPS (Normal-32) @ RTX 2060
- **SDDH**: Sparse Deformable Descriptor Head (å¤‰å½¢å¯èƒ½è¨˜è¿°å­)
- **DKD**: Differentiable Keypoint Detection (sub-pixelç²¾åº¦)
- **Sparse NRE Loss**: å¯†â†’ã‚¹ãƒ‘ãƒ¼ã‚¹ã«ç·©å’Œã—ãŸå­¦ç¿’

**ã‚¿ã‚¹ã‚¯:**
- Keypoint Detection (ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡º)
- Descriptor Extraction (è¨˜è¿°å­æŠ½å‡º)
- Image Matching (ç”»åƒãƒãƒƒãƒãƒ³ã‚°)

**æ€§èƒ½** (HPatches @ 5K keypoints):
- ALIKED-T(16): 78.70% MHA, 125 FPS
- ALIKED-N(16): 77.22% MHA, 77 FPS
- ALIKED-N(32): 74.44% MHA, 76 FPS

---

## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å…¨ä½“åƒ

```
å…¥åŠ›ç”»åƒ (B, 3, H, W)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Feature Encoding (4ãƒ–ãƒ­ãƒƒã‚¯)     â”‚
â”‚    Block1 (stride=1)  â†’ F1          â”‚
â”‚    Block2 (stride=2)  â†’ F2          â”‚
â”‚    Block3 (stride=8)  â†’ F3 + DCN    â”‚ â† Deformable Conv
â”‚    Block4 (stride=32) â†’ F4 + DCN    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Feature Aggregation              â”‚
â”‚    F1,F2,F3,F4 â†’ Upsample & Concat  â”‚ â†’ F (B, dim, H, W)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Score Map Head (SMH)             â”‚
â”‚    Conv3x3 Ã— 3 + Sigmoid            â”‚ â†’ S (B, 1, H, W)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. DKD (Differentiable Detection)   â”‚
â”‚    - NMS (2å›é©ç”¨)                   â”‚
â”‚    - Thresholding & Top-K           â”‚
â”‚    - Soft-argmax refinement         â”‚ â†’ Keypoints (B, N, 2)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                Scores (B, N)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. SDDH (Sparse Deformable Desc)    â”‚
â”‚    - KÃ—Kãƒ‘ãƒƒãƒæŠ½å‡º                   â”‚
â”‚    - Mãƒ‡formableä½ç½®æ¨å®š             â”‚
â”‚    - å¤‰å½¢å¯èƒ½ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°             â”‚
â”‚    - è¨˜è¿°å­é›†ç´„                      â”‚ â†’ Descriptors (B, N, dim)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. Loss (è¨“ç·´æ™‚)                     â”‚
â”‚    - Reprojection Loss              â”‚
â”‚    - Peaky Loss                     â”‚
â”‚    - Sparse NRE Loss                â”‚
â”‚    - Reliable Loss                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ

### 1. [main_flow.py](main_flow.py) (14KB)
**ALIKEDã®å…¨ä½“ãƒ•ãƒ­ãƒ¼**

ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹ `ALIKED` ã§5æ®µéšå‡¦ç†ã‚’å®Ÿè£…:
- Stage 1: Feature Encoding (Multi-scale)
- Stage 2: Feature Aggregation
- Stage 3: Score Map Estimation
- Stage 4: Differentiable Keypoint Detection
- Stage 5: Sparse Deformable Descriptor Extraction

```python
class ALIKED(nn.Module):
    def forward(self, images, top_k=5000, scores_th=0.2):
        # images: (B, 3, H, W)

        # Feature Encoding & Aggregation
        features = self.encode_and_aggregate(images)  # (B, dim, H, W)

        # Score Map
        score_map = self.score_head(features)  # (B, 1, H, W)

        # Keypoint Detection
        keypoints, scores = self.dkd(score_map)  # (B, N, 2), (B, N)

        # Descriptor Extraction
        descriptors = self.sddh(features, keypoints)  # (B, N, dim)

        return {'keypoints': keypoints, 'descriptors': descriptors, ...}
```

**ãƒ¢ãƒ‡ãƒ«ãƒãƒªã‚¢ãƒ³ãƒˆ:**
| Model | Channels | Dim | M | Size | FPS | Use Case |
|-------|----------|-----|---|------|-----|----------|
| aliked-t16 | 8,16,32,64 | 64 | 16 | 0.19M | 126 FPS | Mobile/Real-time |
| aliked-n16 | 16,32,64,128 | 128 | 16 | 0.68M | 77 FPS | Standard |
| aliked-n32 | 16,32,64,128 | 128 | 32 | 0.98M | 76 FPS | High accuracy |

---

### 2. [blocks.py](blocks.py) (18KB)
**Building Blocks**

#### ğŸ”‘ **ã‚­ãƒ¼ãƒ»ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³: SDDH (Sparse Deformable Descriptor Head)**

```python
class SDDH(nn.Module):
    """
    å¾“æ¥æ‰‹æ³• (DMH: Dense Descriptor Map Head):
      - å…¨ãƒ”ã‚¯ã‚»ãƒ«ã§è¨˜è¿°å­è¨ˆç®—: O(H Ã— W Ã— C^2)
      - ãƒ¡ãƒ¢ãƒª: H Ã— W Ã— C
      - å†—é•·: ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå‘¨è¾ºä»¥å¤–ã‚‚è¨ˆç®—

    SDDH (Sparse Deformable Descriptor Head):
      - ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®ã¿: O(N Ã— M Ã— C)
      - ãƒ¡ãƒ¢ãƒª: N Ã— C
      - åŠ¹ç‡: 300å€ä»¥ä¸Šé«˜é€ŸåŒ–!

    å‡¦ç†ãƒ•ãƒ­ãƒ¼:
      1. ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå‘¨è¾ºKÃ—Kãƒ‘ãƒƒãƒæŠ½å‡º
      2. Må€‹ã®å¤‰å½¢å¯èƒ½ã‚µãƒ³ãƒ—ãƒ«ä½ç½®æ¨å®š
      3. å¤‰å½¢å¯èƒ½ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
      4. è¨˜è¿°å­é›†ç´„

    å¤‰å½¢å¯èƒ½æ€§:
      - å„ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã§æœ€é©ãªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ä½ç½®ã‚’å­¦ç¿’
      - å¹¾ä½•å­¦çš„å¤‰æ›ã«å¯¾ã™ã‚‹ä¸å¤‰æ€§ã‚’ç²å¾—
    """

    def forward(self, features, keypoints):
        # features: (B, dim, H, W)
        # keypoints: (B, N, 2)

        # Step 1: KÃ—Kãƒ‘ãƒƒãƒæŠ½å‡º
        patches = self._extract_patches(features, keypoints, K=3)

        # Step 2: Mãƒ‡formableä½ç½®æ¨å®š
        offsets = self.offset_net(patches)  # (B*N, M, 2)

        # Step 3: å¤‰å½¢å¯èƒ½ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        sampled = self._sample_features(features, keypoints + offsets)

        # Step 4: é›†ç´„
        descriptors = sampled.mean(dim=2)  # Average pooling
        descriptors = F.normalize(descriptors, p=2, dim=-1)

        return descriptors  # (B, N, dim)
```

#### ãã®ä»–ã®ãƒ–ãƒ­ãƒƒã‚¯

- **ConvBlock**: åŸºæœ¬ç•³ã¿è¾¼ã¿ (Conv3x3 Ã— 2 + BN + SELU)
- **ResBlock**: æ®‹å·®ãƒ–ãƒ­ãƒƒã‚¯ (Deformable Convå¯¾å¿œ)
- **DeformableConv2d**: å¤‰å½¢å¯èƒ½ç•³ã¿è¾¼ã¿ (DCNv2é¢¨)

**å®Ÿè£…**: [blocks.py:81-340](blocks.py)

---

### 3. [soft_detect.py](soft_detect.py) (11KB)
**Differentiable Keypoint Detection (DKD)**

#### ğŸ”‘ **ã‚­ãƒ¼ãƒ»ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³: Sub-pixel Soft-argmax**

```python
class DKD(nn.Module):
    """
    å¾“æ¥æ‰‹æ³•:
      - NMS â†’ ãƒ”ã‚¯ã‚»ãƒ«ãƒ¬ãƒ™ãƒ«ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ
      - å¾®åˆ†ä¸å¯èƒ½ â†’ end-to-endå­¦ç¿’å›°é›£

    DKD:
      - NMS â†’ Soft-argmax refinement
      - å®Œå…¨ã«å¾®åˆ†å¯èƒ½
      - Sub-pixelç²¾åº¦

    å‡¦ç†:
      1. NMS (2å›) â†’ å±€æ‰€æœ€å¤§å€¤
      2. Thresholding & Top-K
      3. Soft-argmax â†’ sub-pixel refinement
    """

    def _soft_argmax_refine(self, score_map, keypoints_pix):
        """
        Soft-argmax ã«ã‚ˆã‚‹ Sub-pixel refinement

        æ•°å¼:
        p_refined = Î£ (p_i Ã— exp(s_i / T)) / Î£ exp(s_i / T)

        åŠ¹æœ:
        - ãƒ”ã‚¯ã‚»ãƒ«ãƒ¬ãƒ™ãƒ«: [50, 60]
        - Sub-pixel: [50.3, 60.7] â† ã‚ˆã‚Šæ­£ç¢º!
        """
        # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å†…ã§softmax weighted average
        # Temperature T ã§é‹­ã•èª¿æ•´ (T=0.1)
```

#### Score Dispersity

```python
def compute_score_dispersity(score_map, keypoints):
    """
    ã‚¹ã‚³ã‚¢ã®åˆ†æ•£åº¦æ¸¬å®š:
    - ä½åˆ†æ•£ â†’ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆä½ç½®ãŒç¢ºå®Ÿ
    - é«˜åˆ†æ•£ â†’ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆä½ç½®ãŒä¸ç¢ºå®Ÿ

    Peaky Lossã®è¨“ç·´ç›®æ¨™
    """
```

**å®Ÿè£…**: [soft_detect.py:43-180](soft_detect.py)

---

### 4. [loss_computation.py](loss_computation.py) (20KB)
**5ã¤ã®æå¤±é–¢æ•°**

#### ğŸ”‘ **ã‚­ãƒ¼ãƒ»ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³: Sparse NRE Loss**

```python
class ALIKEDLossWrapper(nn.Module):
    """
    å¾“æ¥ã®NRE Loss (Neural Reprojection Error):
      - å¯†ãªè¨˜è¿°å­ãƒãƒƒãƒ—ãŒå¿…è¦
      - 2Dç¢ºç‡ãƒãƒƒãƒ—æ§‹ç¯‰: (H, W)
      - Cross-entropy loss
      - GPU memory: å¤§é‡

    Sparse NRE Loss:
      - ã‚¹ãƒ‘ãƒ¼ã‚¹è¨˜è¿°å­ã®ã¿
      - 1Dç¢ºç‡ãƒ™ã‚¯ãƒˆãƒ«æ§‹ç¯‰: (N_keypoints,)
      - GPU memory: 50å€å‰Šæ¸›!

    å‡¦ç†:
      1. å¹¾ä½•çš„å¯¾å¿œ â†’ Reprojection Probability (binary)
      2. è¨˜è¿°å­é¡ä¼¼åº¦ â†’ Matching Probability (softmax)
      3. Cross-Entropyæœ€å°åŒ–
    """

    def _sparse_nre_loss(self, outputs_a, outputs_b, H_ab):
        # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆAã‚’Image Bã«æŠ•å½±
        kpts_a_warped = warp_keypoints(kpts_a, H_ab)

        # æœ€è¿‘å‚ãƒãƒƒãƒãƒ³ã‚°
        matches = find_nearest_neighbors(kpts_a_warped, kpts_b)

        for idx_a, idx_b in matches:
            # è¨˜è¿°å­é¡ä¼¼åº¦
            sim = desc_b @ desc_a[idx_a]  # (N_b,)

            # Matching probability vector
            q_m = softmax((sim - 1.0) / t_des)  # (N_b,)

            # Loss: -log(matching probability)
            loss += -log(q_m[idx_b])
```

#### ãã®ä»–ã®æå¤±

**1. Reprojection Loss**:
```python
def _reprojection_loss(outputs_a, outputs_b, H_ab):
    """
    ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®å¹¾ä½•çš„æ•´åˆæ€§

    L_rp = 1/2 * (||pA - pBA|| + ||pB - pAB||)

    - pA â†’ Image B ã«æŠ•å½± â†’ pAB
    - pB â†’ Image A ã«æŠ•å½± â†’ pBA
    - åŒæ–¹å‘è·é›¢ã‚’æœ€å°åŒ–
    """
```

**2. Peaky Loss**:
```python
def _peaky_loss(outputs_a, outputs_b):
    """
    ã‚¹ã‚³ã‚¢ãƒãƒƒãƒ—ã®é‹­ã•å¼·åŒ–

    L_pk = mean(softmax(s_patch) Â· ||p - c||)

    - ã‚¹ã‚³ã‚¢ãŒé‹­ããƒ”ãƒ¼ã‚¯ã‚’æŒã¤ã‚ˆã†ã«è¨“ç·´
    - Score dispersityæœ€å°åŒ–
    """
```

**3. Reliable Loss**:
```python
def _reliable_loss(outputs_a, outputs_b):
    """
    è¨˜è¿°å­ã®ä¿¡é ¼æ€§è€ƒæ…®

    L_re = Î£ (1 - r(pA, I_B)) * sA

    - æ˜ç¢ºã«ãƒãƒƒãƒã™ã‚‹ â†’ é«˜ä¿¡é ¼æ€§ â†’ é«˜ã‚¹ã‚³ã‚¢
    - æ›–æ˜§ãªãƒãƒƒãƒ â†’ ä½ä¿¡é ¼æ€§ â†’ ä½ã‚¹ã‚³ã‚¢
    """
```

**æå¤±é‡ã¿**:
- w_rp: 1.0
- w_pk: 0.5
- w_ds: 5.0 (æœ€ã‚‚é‡è¦)
- w_re: 1.0

**å®Ÿè£…**: [loss_computation.py:28-540](loss_computation.py)

---

## ALIKEDã®ä¸»è¦ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³

### 1. **SDDH (Sparse Deformable Descriptor Head)**
**å•é¡Œ**: å¯†ãªè¨˜è¿°å­ãƒãƒƒãƒ—è¨ˆç®—ã¯å†—é•·ã‹ã¤é«˜ã‚³ã‚¹ãƒˆ

**è§£æ±º**:
- ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®ã¿ã§è¨˜è¿°å­æŠ½å‡º
- å„ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã§Må€‹ã®å¤‰å½¢å¯èƒ½ã‚µãƒ³ãƒ—ãƒ«ä½ç½®ã‚’å­¦ç¿’
- å¹¾ä½•å­¦çš„å¤‰æ›ã«å¯¾ã™ã‚‹ä¸å¤‰æ€§ã‚’ç²å¾—

**åŠ¹æœ**:
- è¨ˆç®—é‡: 300å€å‰Šæ¸› (HÃ—WÃ—CÂ² â†’ NÃ—MÃ—C)
- ãƒ¡ãƒ¢ãƒª: 50å€å‰Šæ¸› (HÃ—WÃ—C â†’ NÃ—C)
- ç²¾åº¦: åŒç­‰ä»¥ä¸Š (+1.5% MHA)

**å®Ÿè£…**: [blocks.py:81-340](blocks.py)

---

### 2. **DKD (Differentiable Keypoint Detection)**
**å•é¡Œ**: å¾“æ¥ã®NMSã¯å¾®åˆ†ä¸å¯èƒ½ â†’ end-to-endå­¦ç¿’å›°é›£

**è§£æ±º**:
- Soft-argmaxã«ã‚ˆã‚‹sub-pixel refinement
- å®Œå…¨ã«å¾®åˆ†å¯èƒ½
- Score dispersityã§ä¿¡é ¼åº¦è©•ä¾¡

**åŠ¹æœ**:
- Sub-pixelç²¾åº¦: Â±0.5ãƒ”ã‚¯ã‚»ãƒ«ä»¥ä¸‹
- Reprojection errorç›´æ¥æœ€é©åŒ–å¯èƒ½
- MHA: +2.1% å‘ä¸Š

**å®Ÿè£…**: [soft_detect.py:43-180](soft_detect.py)

---

### 3. **Sparse NRE Loss**
**å•é¡Œ**: å¯†ãªNRE Lossã¯å¤§é‡ã®GPUãƒ¡ãƒ¢ãƒªå¿…è¦

**è§£æ±º**:
- 2Dç¢ºç‡ãƒãƒƒãƒ— â†’ 1Dç¢ºç‡ãƒ™ã‚¯ãƒˆãƒ«ã«ç·©å’Œ
- ã‚¹ãƒ‘ãƒ¼ã‚¹è¨˜è¿°å­ã®ã¿ã§å­¦ç¿’
- è¨˜è¿°å­ãƒãƒƒãƒãƒ³ã‚°å“è³ªã‚’ç›´æ¥æœ€é©åŒ–

**åŠ¹æœ**:
- GPUãƒ¡ãƒ¢ãƒª: 50å€å‰Šæ¸› (800Ã—800è¨“ç·´ã§11GB â†’ 3GB)
- è¨“ç·´é€Ÿåº¦: 3å€é«˜é€ŸåŒ–
- ç²¾åº¦: ã»ã¼åŒç­‰ (-0.5% MHA)

**å®Ÿè£…**: [loss_computation.py:150-260](loss_computation.py)

---

### 4. **Deformable Convolution (Block3&4)**
**å•é¡Œ**: é€šå¸¸ã®Convã¯å›ºå®šå—å®¹é‡ â†’ å¹¾ä½•å­¦çš„ä¸å¤‰æ€§ä¸è¶³

**è§£æ±º**:
- å­¦ç¿’å¯èƒ½ãªã‚ªãƒ•ã‚»ãƒƒãƒˆã§æŸ”è»Ÿãªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
- å„ãƒ”ã‚¯ã‚»ãƒ«ã§æœ€é©ãªå—å®¹é‡ã‚’ç²å¾—
- Block3&4ã®ã¿ä½¿ç”¨ (åŠ¹ç‡ã®ãŸã‚)

**åŠ¹æœ**:
- å¹¾ä½•å­¦çš„ä¸å¤‰æ€§: å¤§å¹…å‘ä¸Š
- Rotation/Scale/Viewpointå¤‰åŒ–ã«é ‘å¥
- è¨ˆç®—é‡å¢—åŠ : ã‚ãšã‹ (+0.1 GFLOPs)

**å®Ÿè£…**: [blocks.py:50-80](blocks.py)

---

## å‡¦ç†ãƒ•ãƒ­ãƒ¼è©³ç´°

### æ¨è«–ãƒ•ãƒ­ãƒ¼

```python
# 1. ç”»åƒå…¥åŠ›
images = torch.randn(2, 3, 640, 480)  # (B, 3, H, W)

# 2. Feature Encoding (4 blocks)
x1 = block1(images)                   # (B, 16, 640, 480) stride=1
x2 = block2(pool2(x1))                # (B, 32, 320, 240) stride=2
x3 = block3_dcn(pool3(x2))            # (B, 64, 80, 60)   stride=8
x4 = block4_dcn(pool4(x3))            # (B, 128, 20, 15)  stride=32

# 3. Feature Aggregation
f1 = ublock1(x1)                      # (B, 32, 640, 480)
f2 = ublock2(x2)                      # (B, 32, 640, 480)
f3 = ublock3(x3)                      # (B, 32, 640, 480)
f4 = ublock4(x4)                      # (B, 32, 640, 480)
features = concat([f1, f2, f3, f4])   # (B, 128, 640, 480)

# 4. Score Map
score_map = score_head(features)      # (B, 1, 640, 480)

# 5. Keypoint Detection
nms_map = simple_nms(score_map) Ã— 2   # 2å›NMS
keypoints_pix = threshold_topk(nms_map, top_k=1000, th=0.2)
keypoints = soft_argmax_refine(score_map, keypoints_pix)  # Sub-pixel
# keypoints: (B, N, 2), N â‰¤ 1000

# 6. Descriptor Extraction
patches = extract_patches(features, keypoints, K=3)       # (B*N, 128, 3, 3)
offsets = offset_net(patches)                             # (B*N, M, 2)
sampled = sample_features(features, keypoints + offsets)  # (B, N, M, 128)
descriptors = aggregate(sampled)                          # (B, N, 128)
descriptors = F.normalize(descriptors, p=2, dim=-1)

# 7. Output
outputs = {
    'keypoints': keypoints,       # (B, N, 2)
    'descriptors': descriptors,   # (B, N, 128)
    'scores': scores,             # (B, N)
    'score_map': score_map        # (B, 1, 640, 480)
}
```

---

### è¨“ç·´ãƒ•ãƒ­ãƒ¼

```python
# 1. ç”»åƒãƒšã‚¢
img_a = torch.randn(2, 3, 800, 800)
img_b = torch.randn(2, 3, 800, 800)
H_ab = get_homography()  # or depth, R, t for perspective

# 2. ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹
out_a = model(img_a)
out_b = model(img_b)

# 3. æå¤±è¨ˆç®—
losses = loss_wrapper(out_a, out_b, H_ab)
# losses = {
#     'loss_rp': Reprojection Loss
#     'loss_pk': Peaky Loss
#     'loss_ds': Sparse NRE Loss
#     'loss_re': Reliable Loss
#     'total_loss': Weighted sum
# }

# 4. ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
total_loss = losses['total_loss']
total_loss.backward()
optimizer.step()
```

**è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**:
- MegaDepth (135 scenes, 10K pairs/scene): Perspective
- R2D2 Homographic: Homography augmentation

**è¨“ç·´è¨­å®š**:
- Resolution: 800Ã—800
- Batch size: 2 (gradient accumulation: 6)
- Top-K keypoints: 400 (detection) + 400 (random)
- Steps: 100K
- Optimizer: Adam (betas: 0.9, 0.999)

---

## å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ

ALIKEDã¯2ç¨®é¡ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå½¢å¼ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™:

### 1. Homographic Dataset (åˆæˆãƒ‡ãƒ¼ã‚¿)

**ç‰¹å¾´**:
- ã‚«ãƒ¡ãƒ©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¸è¦
- 1æšã®ç”»åƒã‹ã‚‰åˆæˆãƒšã‚¢ã‚’ç”Ÿæˆ
- å¹¾ä½•å¤‰æ›ã®ã¿ã§å¯¾å¿œé–¢ä¿‚ã‚’ç”Ÿæˆ

**å‡¦ç†ãƒ•ãƒ­ãƒ¼**:
```python
# 1. ç”»åƒã‚’1æšãƒ­ãƒ¼ãƒ‰
image = load_image("photo.jpg")  # (H, W, 3)

# 2. ãƒ©ãƒ³ãƒ€ãƒ ãªHomographyè¡Œåˆ—ã‚’ç”Ÿæˆ
H_ab = generate_random_homography()  # (3, 3)
# H = Translation Ã— Rotation Ã— Scale Ã— Shear Ã— Perspective

# 3. ç”»åƒã‚’ãƒ¯ãƒ¼ãƒ—ã—ã¦ç”»åƒãƒšã‚¢ã‚’ä½œæˆ
image_a = image
image_b = warp_image(image, H_ab)

# 4. å¹¾ä½•çš„å¯¾å¿œé–¢ä¿‚ã¯æ—¢çŸ¥
# ç‚¹p_aã¯ H_ab @ p_a ã§ p_b ã«å¤‰æ›ã•ã‚Œã‚‹
```

**ãƒ‡ãƒ¼ã‚¿æ§‹æˆ**:
- å…¥åŠ›: å˜ä¸€ç”»åƒã®ã¿
- ãƒ©ãƒ™ãƒ«: Homographyè¡Œåˆ— `H_ab` (3Ã—3) - å®Ÿè¡Œæ™‚ã«ç”Ÿæˆ
- åˆ©ç‚¹: å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’åŠ¹ç‡çš„ã«ç”Ÿæˆå¯èƒ½

### 2. Perspective Dataset (å®Ÿç”»åƒãƒšã‚¢ - MegaDepth)

**ç‰¹å¾´**:
- å®Ÿéš›ã®ç”»åƒãƒšã‚¢ã‚’ä½¿ç”¨
- COLMAPã§äº‹å‰è¨ˆç®—ã•ã‚ŒãŸã‚«ãƒ¡ãƒ©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’åˆ©ç”¨
- å¥¥è¡Œãæƒ…å ±ã‚’å«ã‚€

**ãƒ‡ãƒ¼ã‚¿æ§‹æˆ**:
å„ã‚·ãƒ¼ãƒ³ã«å¯¾ã—ã¦ `scene_info.npz` ãŒå­˜åœ¨:
```python
scene_info = {
    'intrinsics': (N, 3, 3),    # ã‚«ãƒ¡ãƒ©å†…éƒ¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ K
    'poses': (N, 4, 4),          # ã‚«ãƒ¡ãƒ©ãƒãƒ¼ã‚º [R|t]
    'depth_paths': List[str],    # å„ç”»åƒã®æ·±åº¦ãƒãƒƒãƒ—ãƒ‘ã‚¹
    'pairs': List[(i, j)],       # ç”»åƒãƒšã‚¢ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    'image_paths': List[str]     # ç”»åƒãƒ‘ã‚¹
}
```

**ãƒ‡ãƒ¼ã‚¿å–å¾—ä¾‹**:
```python
# ãƒšã‚¢ (i, j) ã‚’ãƒ­ãƒ¼ãƒ‰
pair_idx = (5, 12)
image_a = load_image(scene_info['image_paths'][5])
image_b = load_image(scene_info['image_paths'][12])
depth_a = load_depth(scene_info['depth_paths'][5])

# ã‚«ãƒ¡ãƒ©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
K_a = scene_info['intrinsics'][5]      # (3, 3)
K_b = scene_info['intrinsics'][12]     # (3, 3)

# ã‚«ãƒ¡ãƒ©ãƒãƒ¼ã‚ºã‹ã‚‰ç›¸å¯¾å¤‰æ›ã‚’è¨ˆç®—
pose_a = scene_info['poses'][5]        # (4, 4) = [R_a | t_a]
pose_b = scene_info['poses'][12]       # (4, 4) = [R_b | t_b]

# ç›¸å¯¾ãƒãƒ¼ã‚ºè¨ˆç®—: b = R_ab @ a + t_ab
T_ab = pose_b @ np.linalg.inv(pose_a)
R_ab = T_ab[:3, :3]  # (3, 3)
t_ab = T_ab[:3, 3]   # (3,)
```

**å¹¾ä½•çš„å¯¾å¿œé–¢ä¿‚ã®è¨ˆç®—**:
```python
# ç”»åƒAä¸Šã®ç‚¹ p_a = (x_a, y_a) ã«å¯¾ã—ã¦ã€ç”»åƒBä¸Šã®å¯¾å¿œç‚¹ã‚’è¨ˆç®—

# 1. ãƒ”ã‚¯ã‚»ãƒ«åº§æ¨™ â†’ ã‚«ãƒ¡ãƒ©åº§æ¨™
p_cam_a = K_a_inv @ [x_a, y_a, 1] * depth_a[y_a, x_a]

# 2. ã‚«ãƒ¡ãƒ©Aã‹ã‚‰ã‚«ãƒ¡ãƒ©Bã¸å¤‰æ›
p_cam_b = R_ab @ p_cam_a + t_ab

# 3. ã‚«ãƒ¡ãƒ©åº§æ¨™ â†’ ãƒ”ã‚¯ã‚»ãƒ«åº§æ¨™
p_b = K_b @ p_cam_b
x_b, y_b = p_b[0] / p_b[2], p_b[1] / p_b[2]
```

### è¨“ç·´æ™‚ã®ä½¿ç”¨æ–¹æ³•

**Homographic Dataset**:
```python
dataset = HomographicDataset(
    image_paths=glob("images/*.jpg"),
    image_size=(800, 800)
)
# è¿”ã‚Šå€¤: image_a, image_b, H_ab
```

**Perspective Dataset**:
```python
dataset = MegaDepthDataset(
    scene_info_dir="/path/to/megadepth/scene_info/",
    image_size=(800, 800)
)
# è¿”ã‚Šå€¤: image_a, image_b, depth_a, K_a, K_b, R_ab, t_ab
```

**è©³ç´°å®Ÿè£…**: [training_data.py](training_data.py) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®å®Œå…¨ãªå®Ÿè£…ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚

---

## å½¢çŠ¶ã‚¬ã‚¤ãƒ‰

### å…¥åŠ›ãƒ»ä¸­é–“ãƒ»å‡ºåŠ›å½¢çŠ¶

| æ®µéš | åç§° | å½¢çŠ¶ | èª¬æ˜ |
|------|------|------|------|
| **å…¥åŠ›** | images | `(B, 3, H, W)` | RGBç”»åƒ |
| **Encoding** | x1 | `(B, c1, H, W)` | Block1å‡ºåŠ› (stride=1) |
| | x2 | `(B, c2, H/2, W/2)` | Block2å‡ºåŠ› (stride=2) |
| | x3 | `(B, c3, H/8, W/8)` | Block3å‡ºåŠ› (stride=8, DCN) |
| | x4 | `(B, c4, H/32, W/32)` | Block4å‡ºåŠ› (stride=32, DCN) |
| **Aggregation** | features | `(B, dim, H, W)` | çµ±åˆç‰¹å¾´ |
| **Score Map** | score_map | `(B, 1, H, W)` | ã‚¹ã‚³ã‚¢ãƒãƒƒãƒ— [0,1] |
| **Keypoints** | keypoints | `(B, N, 2)` | Sub-pixelåº§æ¨™ `[x, y]` |
| | scores | `(B, N)` | ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚¹ã‚³ã‚¢ [0,1] |
| **Descriptors** | descriptors | `(B, N, dim)` | L2æ­£è¦åŒ–è¨˜è¿°å­ |
| **SDDHå†…éƒ¨** | patches | `(B*N, dim, K, K)` | ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ‘ãƒƒãƒ (K=3) |
| | offsets | `(B*N, M, 2)` | å¤‰å½¢å¯èƒ½ã‚ªãƒ•ã‚»ãƒƒãƒˆ |
| | sampled | `(B, N, M, dim)` | ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‰¹å¾´ |

### è»¸ã®æ„å‘³

- **B**: ãƒãƒƒãƒã‚µã‚¤ã‚º
- **3**: RGB ãƒãƒ£ãƒãƒ«
- **H, W**: ç”»åƒã®é«˜ã•ãƒ»å¹…
- **H/N, W/N**: Nå€ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å¾Œã®é«˜ã•ãƒ»å¹…
- **c1~c4**: å„ãƒ–ãƒ­ãƒƒã‚¯ã®ãƒãƒ£ãƒãƒ«æ•° (ãƒ¢ãƒ‡ãƒ«ãƒãƒªã‚¢ãƒ³ãƒˆã§ç•°ãªã‚‹)
- **dim**: è¨˜è¿°å­æ¬¡å…ƒ (64 for Tiny, 128 for Normal)
- **N**: ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ•° (top_kã§åˆ¶å¾¡, é€šå¸¸ â‰¤ 5000)
- **M**: å¤‰å½¢å¯èƒ½ã‚µãƒ³ãƒ—ãƒ«ä½ç½®æ•° (16 or 32)
- **K**: ãƒ‘ãƒƒãƒã‚µã‚¤ã‚º (3 or 5)

---

## FAQ

### Q1: ALIKEDã¨å¾“æ¥æ‰‹æ³• (SuperPoint, R2D2) ã®é•ã„ã¯?

**A**: ä¸»ãªé•ã„ã¯3ç‚¹:

1. **è¨˜è¿°å­æŠ½å‡ºæ–¹æ³•**
   - SuperPoint/R2D2: å¯†ãªè¨˜è¿°å­ãƒãƒƒãƒ—ã‚’å…¨ä½“ã§è¨ˆç®— â†’ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
   - ALIKED: ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®ã¿ã§è¨˜è¿°å­æŠ½å‡º (SDDH)
   - åŠ¹æœ: 300å€é«˜é€ŸåŒ–, 50å€ãƒ¡ãƒ¢ãƒªå‰Šæ¸›

2. **å¹¾ä½•å­¦çš„ä¸å¤‰æ€§**
   - SuperPoint/R2D2: é€šå¸¸ã®Conv â†’ å›ºå®šå—å®¹é‡
   - ALIKED: Deformable Conv + SDDH â†’ é©å¿œçš„å—å®¹é‡
   - åŠ¹æœ: Rotation/Scale/Viewpointå¤‰åŒ–ã«é ‘å¥

3. **ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡º**
   - SuperPoint/R2D2: å¾®åˆ†ä¸å¯èƒ½ãªNMS
   - ALIKED: Differentiable Soft-argmax (DKD)
   - åŠ¹æœ: Sub-pixelç²¾åº¦, end-to-endå­¦ç¿’

**çµæœ**: HPatches 78.70% MHA @ 126 FPS (ALIKED-T vs SuperPoint 70.19% @ 53 FPS)

---

### Q2: SDDHã®å¤‰å½¢å¯èƒ½æ€§ã¯ã©ã†æ©Ÿèƒ½ã™ã‚‹?

**A**: å„ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã§æœ€é©ãªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ä½ç½®ã‚’å­¦ç¿’ã—ã¾ã™ã€‚

**é€šå¸¸ã®è¨˜è¿°å­**:
```python
# å›ºå®šã‚°ãƒªãƒƒãƒ‰ (ä¾‹: 3x3)
positions = [
    [-1,-1], [-1,0], [-1,1],
    [0,-1],  [0,0],  [0,1],
    [1,-1],  [1,0],  [1,1]
]
descriptor = aggregate(features[keypoint + positions])
```

**SDDH (å¤‰å½¢å¯èƒ½)**:
```python
# å­¦ç¿’å¯èƒ½ãªã‚ªãƒ•ã‚»ãƒƒãƒˆ
offsets = offset_net(patch)  # Network learns optimal positions
positions = deformable_positions + offsets  # Adaptive!

# ä¾‹: Rotated feature
offsets = [
    [-0.7,0.7], [0,1], [0.7,0.7],
    [-1,0],     [0,0], [1,0],
    [-0.7,-0.7],[0,-1],[0.7,-0.7]
]  # Automatically adapts to rotation!

descriptor = aggregate(features[keypoint + offsets])
```

**åˆ©ç‚¹**:
- Rotation: ã‚ªãƒ•ã‚»ãƒƒãƒˆãŒå›è»¢æ–¹å‘ã«é©å¿œ
- Scale: ã‚ªãƒ•ã‚»ãƒƒãƒˆã®å¤§ãã•ãŒé©å¿œ
- Perspective: è¤‡é›‘ãªå¤‰å½¢ã«ã‚‚å¯¾å¿œ

**å¯è¦–åŒ–**: è«–æ–‡ Fig.7 å‚ç…§

---

### Q3: Sparse NRE Lossã®ãƒ¡ãƒ¢ãƒªå‰Šæ¸›åŠ¹æœã¯?

**A**: ç´„50å€ã®ãƒ¡ãƒ¢ãƒªå‰Šæ¸›ã§ã™ã€‚

**Dense NRE Loss**:
```python
# å¯†ãªè¨˜è¿°å­ãƒãƒƒãƒ—å¿…è¦
desc_map_a = dense_head(features_a)  # (B, dim, H, W)
desc_map_b = dense_head(features_b)  # (B, dim, H, W)

# 2Dç¢ºç‡ãƒãƒƒãƒ—æ§‹ç¯‰
prob_map_a = compute_probability_map(desc_map_a, desc_map_b)
# (B, H, W, H, W) â† éå¸¸ã«å¤§ãã„!

# Memory: B Ã— H Ã— W Ã— dim Ã— 4 bytes
# ä¾‹: 2 Ã— 800 Ã— 800 Ã— 128 Ã— 4 = 655 MB per batch
```

**Sparse NRE Loss (ALIKED)**:
```python
# ã‚¹ãƒ‘ãƒ¼ã‚¹è¨˜è¿°å­ã®ã¿
desc_a = sddh(features_a, keypoints_a)  # (B, N, dim)
desc_b = sddh(features_b, keypoints_b)  # (B, N, dim)

# 1Dç¢ºç‡ãƒ™ã‚¯ãƒˆãƒ«æ§‹ç¯‰
for each match (kpt_a, kpt_b):
    prob_vec = softmax(desc_b @ desc_a)  # (N_b,) â† å°ã•ã„!

# Memory: B Ã— N Ã— dim Ã— 4 bytes
# ä¾‹: 2 Ã— 800 Ã— 128 Ã— 4 = 0.8 MB per batch
```

**å‰Šæ¸›ç‡**: 655 MB / 0.8 MB â‰ˆ 820å€ (å®Ÿéš›ã¯~50å€ã€ä»–ã®è¦å› å«ã‚€)

**è¨“ç·´å¯èƒ½æ€§**:
- Dense: 800Ã—800è¨“ç·´ã§11GB GPUå¿…è¦
- Sparse: 800Ã—800è¨“ç·´ã§3GB GPU (Batch size=2, accumulation=6)

---

### Q4: Soft-argmaxã®Sub-pixelç²¾åº¦ã¯ã©ã®ç¨‹åº¦?

**A**: ç´„Â±0.3ãƒ”ã‚¯ã‚»ãƒ«ã®ç²¾åº¦ã§ã™ã€‚

**ãƒ”ã‚¯ã‚»ãƒ«ãƒ¬ãƒ™ãƒ«æ¤œå‡º (é€šå¸¸ã®NMS)**:
```python
# Pixel-level keypoint
kpt_pix = [50, 60]  # Integer coordinates

# å®Ÿéš›ã®æœ€å¤§å€¤ä½ç½®ãŒ [50.7, 60.3] ã ã¨ã—ã¦ã‚‚
# [50, 60] ã«ä¸¸ã‚ã‚‰ã‚Œã‚‹ â†’ èª¤å·® Â±0.5ãƒ”ã‚¯ã‚»ãƒ«
```

**Soft-argmax refinement (ALIKED)**:
```python
# Score patch (5x5 window around pixel [50, 60])
scores = [
    [0.1, 0.2, 0.3, 0.2, 0.1],
    [0.2, 0.4, 0.6, 0.4, 0.2],
    [0.3, 0.6, 0.9, 0.6, 0.3],  # Center at [50, 60]
    [0.2, 0.4, 0.6, 0.4, 0.2],
    [0.1, 0.2, 0.3, 0.2, 0.1]
]

# Weighted average
weights = softmax(scores / temperature)
refined = Î£ (position Ã— weights)
# Result: [50.7, 60.3] â† Sub-pixel!
```

**å®Ÿé¨“çµæœ** (HPatches Repeatability):
- Pixel-level: 40.2%
- Sub-pixel (DKD): 43.4% (+3.2%)

**å¯è¦–åŒ–**: è«–æ–‡ Table IX, Row 7 vs Row 8

---

### Q5: M (ã‚µãƒ³ãƒ—ãƒ«ä½ç½®æ•°) ã¯ã©ã†é¸ã¶?

**A**: é€Ÿåº¦ã¨ç²¾åº¦ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã§ã™ã€‚

**å®Ÿé¨“çµæœ** (IMW-validation):

| M | GFLOPs | Running Time | mAA(10Â°) | MS@3 |
|---|--------|--------------|----------|------|
| 8 | 3.48 | 0.28 ms | 64.72% | 88.28% |
| **16** | **4.05** | **0.57 ms** | **65.39%** | **88.93%** |
| 24 | 4.62 | 0.86 ms | 67.59% | 90.29% |
| 32 | 4.62 | 1.14 ms | 67.78% | 90.12% |

**æ¨å¥¨**:
- **M=16**: æœ€è‰¯ã®ãƒãƒ©ãƒ³ã‚¹ (ALIKED-N16)
  - é€Ÿåº¦: 77 FPS
  - ç²¾åº¦: 77.22% MHA
  - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: 0.68M

- M=32: é«˜ç²¾åº¦ç”¨é€” (ALIKED-N32)
  - é€Ÿåº¦: 76 FPS (ã‚ãšã‹ã«é…ã„)
  - ç²¾åº¦: 74.44% MHA
  - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: 0.98M

**ç†ç”±**: M=16ã§ååˆ†ãªå—å®¹é‡ã‚’ç¢ºä¿ã€M>16ã¯æ€§èƒ½é£½å’Œ

---

### Q6: ãªãœBlock3&4ã®ã¿Deformable Conv?

**A**: åŠ¹ç‡ã¨æ€§èƒ½ã®ãƒãƒ©ãƒ³ã‚¹ã§ã™ã€‚

**å…¨ãƒ–ãƒ­ãƒƒã‚¯ã§DCNä½¿ç”¨ã—ãŸå ´åˆ**:
```python
# Block1 (HÃ—W) + DCN
block1_dcn_flops = H Ã— W Ã— c1^2 Ã— K^2 Ã— 2
# = 640 Ã— 480 Ã— 16^2 Ã— 9 Ã— 2 = 354M

# Block2 (H/2Ã—W/2) + DCN
block2_dcn_flops = (H/2) Ã— (W/2) Ã— c2^2 Ã— K^2 Ã— 2
# = 320 Ã— 240 Ã— 32^2 Ã— 9 Ã— 2 = 354M

# Total: 708M additional FLOPs!
```

**Block3&4ã®ã¿DCNä½¿ç”¨ (ALIKED)**:
```python
# Block3 (H/8Ã—W/8) + DCN
block3_dcn_flops = (H/8) Ã— (W/8) Ã— c3^2 Ã— K^2 Ã— 2
# = 80 Ã— 60 Ã— 64^2 Ã— 9 Ã— 2 = 35M

# Block4 (H/32Ã—W/32) + DCN
block4_dcn_flops = (H/32) Ã— (W/32) Ã— c4^2 Ã— K^2 Ã— 2
# = 20 Ã— 15 Ã— 128^2 Ã— 9 Ã— 2 = 8.8M

# Total: 44M additional FLOPs (acceptable!)
```

**æ€§èƒ½æ¯”è¼ƒ** (IMW-validation):
- No DCN: 57.00% mAA(10Â°)
- Block3&4 DCN: 63.58% mAA(10Â°) (+6.58%)
- All blocks DCN: 64.1% mAA(10Â°) (+0.52%, not worth it)

**çµè«–**: Block3&4ã®DCNã§ååˆ†ãªå¹¾ä½•å­¦çš„ä¸å¤‰æ€§ã‚’ç²å¾—

---

### Q7: è¨“ç·´æ™‚ã¨æ¨è«–æ™‚ã§ä½•ãŒé•ã†?

**A**: ä¸»ã«3ç‚¹ç•°ãªã‚Šã¾ã™ã€‚

**1. ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ•°**:
```python
# è¨“ç·´æ™‚
top_k = 400  # DKD detected
random_k = 400  # Randomly sampled
total = 800  # More diverse for training

# æ¨è«–æ™‚
top_k = 1000~5000  # User specified
random_k = 0
total = top_k
```

**2. æå¤±è¨ˆç®—**:
```python
# è¨“ç·´æ™‚
outputs_a = model(img_a)
outputs_b = model(img_b)
losses = loss_wrapper(outputs_a, outputs_b, H_ab)
total_loss.backward()  # Backpropagation

# æ¨è«–æ™‚
outputs = model(img)
# No loss, no backprop
```

**3. NMSé©ç”¨å›æ•°**:
```python
# è¨“ç·´æ™‚
nms_map = simple_nms(score_map)  # 1å›ã®ã¿ (é«˜é€ŸåŒ–)

# æ¨è«–æ™‚
nms_map = score_map
for _ in range(2):
    nms_map = simple_nms(nms_map)  # 2å› (ç²¾åº¦å‘ä¸Š)
```

**ãã®ä»–ã¯åŒä¸€**: Feature extraction, DKD, SDDH ã¯åŒã˜å‡¦ç†

---

### Q8: ã‚«ã‚¹ã‚¿ãƒ CUDAå®Ÿè£…ã®å½¹å‰²ã¯?

**A**: ãƒ‘ãƒƒãƒæŠ½å‡ºã®é«˜é€ŸåŒ–ã§ã™ã€‚

**PyTorchå®Ÿè£… (æ¨™æº–)**:
```python
def extract_patches_pytorch(features, keypoints, K):
    # Grid sampleä½¿ç”¨
    patches = F.grid_sample(features, grid)
    # é€Ÿåº¦: ~1.0 ms (1000 keypoints)
```

**ã‚«ã‚¹ã‚¿ãƒ CUDAå®Ÿè£…**:
```cpp
// custom_ops/get_patches_cuda.cu
__global__ void extract_patches_kernel(...) {
    // Optimized parallel extraction
}
```

```python
def extract_patches_cuda(features, keypoints, K):
    # Custom CUDA kernel
    patches = get_patches_cuda.forward(features, keypoints, K)
    # é€Ÿåº¦: ~0.3 ms (1000 keypoints) â† 3å€é«˜é€Ÿ!
```

**åˆ©ç‚¹**:
- ä¸¦åˆ—åŒ–æœ€é©åŒ–
- ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³æœ€é©åŒ–
- Backward passæœ€é©åŒ–

**Fallback**: CUDAåˆ©ç”¨ä¸å¯æ™‚ã¯è‡ªå‹•çš„ã«PyTorchå®Ÿè£…ä½¿ç”¨

---

### Q9: ALIKEDã®é™ç•Œã¯?

**A**: ä¸»ã«2ã¤ã®é™ç•ŒãŒã‚ã‚Šã¾ã™ã€‚

**1. å¤§è¦æ¨¡ã‚¹ã‚±ãƒ¼ãƒ«&è¦–ç‚¹å¤‰åŒ–**:
```
å•é¡Œ: ã‚¹ã‚±ãƒ¼ãƒ«å·®4å€ä»¥ä¸Š + è¦–ç‚¹å¤‰åŒ–å¤§

ä¾‹: é æ™¯ãƒ“ãƒ« (scale 1x) â†” è¿‘æ™¯ãƒ“ãƒ« (scale 5x, viewpoint 45Â°)

çµæœ:
- ASLFeat(MS): æ•°ãƒãƒƒãƒå›å¾© (multi-scale strategy)
- DISK: æ•°ãƒãƒƒãƒå›å¾© (å¼·åŠ›ãªè¨˜è¿°å­)
- ALIKED: ã»ã¼å¤±æ•—

ç†ç”±:
- Single-scale feature extraction
- Deformable convã¯1ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ã¿ â†’ é™å®šçš„ãªãƒ¢ãƒ‡ãƒªãƒ³ã‚°
```

**è§£æ±ºç­–**:
- Multi-scale matching strategyè¿½åŠ 
- Deformable convã‚’è¤‡æ•°ãƒ¬ã‚¤ãƒ¤ãƒ¼ã« (ã‚³ã‚¹ãƒˆå¢—)
- Learned matcher (SuperGlueç­‰) ä½µç”¨

**2. ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ã§ãªã„**:
```
å•é¡Œ:
- Grid sampling: æ¨™æº–æ¼”ç®—ã§ãªã„
- Deformable conv: ç‰¹æ®Šãªå®Ÿè£…å¿…è¦
- 32-bit float descriptors: ãƒ¡ãƒ¢ãƒªå¸¯åŸŸå¹…

ãƒ¢ãƒã‚¤ãƒ«ãƒ‡ãƒ—ãƒ­ã‚¤æ™‚:
- TensorRTæœ€é©åŒ–å¿…è¦
- é‡å­åŒ–å¯¾å¿œå¿…è¦
- ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ¼ãƒãƒ«å®Ÿè£…å¿…è¦
```

**ä»Šå¾Œã®æ–¹å‘**:
- Binary descriptors (1-bit) æ¤œè¨
- Hardware-friendly architectureè¨­è¨ˆ

**å®Ÿé¨“çµæœ**: è«–æ–‡ Fig. 8, Section VI-Eå‚ç…§

---

### Q10: ALIKEDã®ãƒ™ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã¯?

**A**: ä»¥ä¸‹ã®ç”¨é€”ã«æœ€é©ã§ã™ã€‚

**1. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ SLAM**:
```
è¦ä»¶:
- é«˜é€Ÿ: >60 FPS
- ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·
- é©åº¦ãªç²¾åº¦

ALIKED-T(16):
- 126 FPS @ RTX 2060
- 0.19M parameters
- 78.70% MHA (SuperPointã‚ˆã‚Šé«˜ã„)

ç”¨é€”: ãƒ‰ãƒ­ãƒ¼ãƒ³SLAM, ãƒ­ãƒœãƒƒãƒˆãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
```

**2. æ¨™æº–ç”»åƒãƒãƒƒãƒãƒ³ã‚°**:
```
è¦ä»¶:
- é«˜ç²¾åº¦
- é©åº¦ãªé€Ÿåº¦
- å¹¾ä½•å­¦çš„ä¸å¤‰æ€§

ALIKED-N(16):
- 77 FPS @ RTX 2060
- 77.22% MHA (SOTAç´š)
- Rotation/Scaleé ‘å¥

ç”¨é€”: SfM, 3Då†æ§‹æˆ, Visual Localization
```

**3. ã‚¨ãƒƒã‚¸ãƒ‡ãƒã‚¤ã‚¹**:
```
è¦ä»¶:
- è¶…è»½é‡
- ä½ãƒ¡ãƒ¢ãƒª
- ãƒãƒƒãƒ†ãƒªãƒ¼åŠ¹ç‡

ALIKED-T(16):
- 0.19M parameters (SuperPointã®1/7)
- 1.37 GFLOPs (SuperPointã®1/19)
- æ¨è«–: 8ms @ GPU

ç”¨é€”: ãƒ¢ãƒã‚¤ãƒ«AR, ã‚¨ãƒƒã‚¸ã‚«ãƒ¡ãƒ©
```

**é¿ã‘ã‚‹ã¹ãã‚±ãƒ¼ã‚¹**:
- è¶…å¤§è¦æ¨¡ã‚¹ã‚±ãƒ¼ãƒ«å¤‰åŒ– (>4x)
- æ¥µç«¯ãªè¦–ç‚¹å¤‰åŒ– + ã‚¹ã‚±ãƒ¼ãƒ«å¤‰åŒ–
- è¶…é«˜ç²¾åº¦è¦æ±‚ (DISK/ASLFeatæ¨å¥¨)

---

## ã¾ã¨ã‚

ALIKEDã¯ä»¥ä¸‹ã®3ã¤ã®ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã§è¶…è»½é‡ãƒ»é«˜é€Ÿãƒ»é«˜ç²¾åº¦ã‚’å®Ÿç¾:

1. **SDDH**: Sparse Deformable Descriptor Head
   - è¨ˆç®—é‡300å€å‰Šæ¸›
   - ãƒ¡ãƒ¢ãƒª50å€å‰Šæ¸›
   - å¹¾ä½•å­¦çš„ä¸å¤‰æ€§ç²å¾—

2. **DKD**: Differentiable Keypoint Detection
   - Sub-pixelç²¾åº¦
   - End-to-endå­¦ç¿’å¯èƒ½
   - Reprojection errorç›´æ¥æœ€é©åŒ–

3. **Sparse NRE Loss**: å¯†â†’ã‚¹ãƒ‘ãƒ¼ã‚¹ç·©å’Œ
   - GPUãƒ¡ãƒ¢ãƒª50å€å‰Šæ¸›
   - è¨“ç·´é€Ÿåº¦3å€å‘ä¸Š
   - é«˜è§£åƒåº¦è¨“ç·´å¯èƒ½

**æ€§èƒ½**: HPatches 78.70% MHA @ 126 FPS (ALIKED-T16)

**ç”¨é€”**:
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ SLAM (ãƒ‰ãƒ­ãƒ¼ãƒ³, ãƒ­ãƒœãƒƒãƒˆ)
- æ¨™æº–ç”»åƒãƒãƒƒãƒãƒ³ã‚° (SfM, 3Då†æ§‹æˆ)
- ã‚¨ãƒƒã‚¸ãƒ‡ãƒã‚¤ã‚¹ (ãƒ¢ãƒã‚¤ãƒ«AR, çµ„ã¿è¾¼ã¿)

**æ¨å¥¨è¨­å®š**:
- Real-time: ALIKED-T(16) - 126 FPS
- Balanced: ALIKED-N(16) - 77 FPS (æ¨å¥¨)
- Accuracy: ALIKED-N(32) - 76 FPS

**åˆ¶é™**:
- å¤§è¦æ¨¡ã‚¹ã‚±ãƒ¼ãƒ«&è¦–ç‚¹å¤‰åŒ–: Multi-scale strategyæ¨å¥¨
- ãƒ¢ãƒã‚¤ãƒ«æœ€é©åŒ–: TensorRT/é‡å­åŒ–å¿…è¦

---

## å‚è€ƒæ–‡çŒ®

- è«–æ–‡: [ALIKED: A Lighter Keypoint and Descriptor Extraction Network via Deformable Transformation](https://arxiv.org/abs/2304.03608)
- ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹: Original ALIKED implementation
- é–¢é€£ç ”ç©¶:
  - SuperPoint (2018): Homographic Adaptation
  - R2D2 (2019): Repeatability and Reliability
  - DISK (2020): Reinforcement Learning
  - ALIKE (2022): Differentiable Keypoint Detection (ALIKEDã®å‰èº«)
  - DCNv2 (2019): Deformable Convolution

---

**Note**: ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç¾¤ã¯ç†è§£ã‚’ç›®çš„ã¨ã—ãŸç°¡ç•¥åŒ–ç–‘ä¼¼ã‚³ãƒ¼ãƒ‰ã§ã™ã€‚å®Ÿéš›ã®å®Ÿè£…ã¨ã¯ç•°ãªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
